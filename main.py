import config
import kernels
import cuda_utils
import llm_api as agents 
import prompts            
import torch
from tqdm import tqdm
import os
import re
import ast
import sys
import json 

def extract_code(response_text):
    """(æ­¤å‡½æ•°ä¿æŒä¸å˜)"""
    if not response_text: return None 
    match = re.search(r'```cuda\n(.*?)```', response_text, re.DOTALL)
    if not match:
        if "torch::Tensor gemm_cuda" in response_text: 
             return response_text
        print("[Coder Agent] Error: No CUDA code block found in response.")
        return None
            
    return match.group(1).strip()

def extract_metrics(response_text):
    """(æ­¤å‡½æ•°ä¿æŒä¸å˜)"""
    if not response_text: return None 
    try:
        metrics_list_str = response_text.split("METRICS:")[1].strip()
        metrics_list = ast.literal_eval(metrics_list_str) 
        return metrics_list
    except Exception as e:
        print(f"[Tool Agent] Error parsing metrics list: {e}\nResponse was: {response_text}")
        return None

# [!!! å·²åˆ é™¤ !!!]
# def get_diverse_champions(history: list, current_best_code: str, num_kernels=2) -> str:
#     ... (æ­¤åŠŸèƒ½è¢« summarize_tree_context æ›¿ä»£)

# [!!! å·²åˆ é™¤ !!!]
# def summarize_history(history: list) -> str:
#     ... (æ­¤åŠŸèƒ½è¢« summarize_tree_context æ›¿ä»£)


# [!!! å·²æ›´æ–° !!!] è§£å†³äº† TODO é—®é¢˜ 5 å’Œ 6ï¼ˆæ ¹æ®æ‚¨çš„æœ€æ–°è¦æ±‚ï¼‰
def format_selected_ncu_metrics(entry):
    """
    ä¸€ä¸ªè¾…åŠ©å‡½æ•°ï¼Œç”¨äºæ ¼å¼åŒ–æ‰€é€‰çš„ NCU æŒ‡æ ‡ä»¥åŒ…å«åœ¨æ‘˜è¦ä¸­ã€‚
    """
    selected_metrics = entry.get('selected_ncu_metrics')
    all_ncu = entry.get('all_ncu_metrics')
    
    if isinstance(selected_metrics, list) and isinstance(all_ncu, dict) and selected_metrics:
        metric_summary = "    Selected NCU Metrics (for Goal):\n"
        for metric_name in selected_metrics:
            value = all_ncu.get(metric_name, 'N/A')
            metric_summary += f"      - {metric_name}: {value}\n"
        return metric_summary
    return ""

# [!!! å·²æ›´æ–° !!!] è§£å†³äº† TODO é—®é¢˜ 6
def summarize_tree_context(history: list, best_node: dict, max_ancestors=5, max_children=10) -> str:
    """
    åŸºäºå½“å‰çš„æœ€ä½³èŠ‚ç‚¹ï¼Œç”Ÿæˆç”¨äºæç¤ºçš„"æ ‘ä¸Šä¸‹æ–‡"ã€‚
    åŒ…æ‹¬"è¿‘æœŸæˆåŠŸè·¯å¾„"ï¼ˆç¥–å…ˆï¼‰å’Œ"è¿‘æœŸå¤±è´¥å°è¯•"ï¼ˆå­èŠ‚ç‚¹ï¼‰ã€‚
    
    [!!! å·²æ›´æ–° !!!]
    - æˆåŠŸè·¯å¾„ç°åœ¨åŒ…å« 'Selected NCU Metrics'ã€‚
    - å¤±è´¥å°è¯•ç°åœ¨åŒ…å« 'Selected NCU Metrics'ã€‚
    - å¤±è´¥å°è¯•åœ¨ 'Failed (Compilation)' æˆ– 'Failed (Correctness)' æ—¶
      ä¼š *æ™ºèƒ½åœ°åŒ…å«* 'Failed Code:'ã€‚
    """
    if not best_node:
        return "No optimization history (starting from baseline)."

    # 1. åˆ›å»ºä¸€ä¸ª map ä»¥ä¾¿å¿«é€ŸæŸ¥æ‰¾
    history_map = {entry['round']: entry for entry in history}
    
    # 2. ç”Ÿæˆ "Recent Success Path" (ç¥–å…ˆ)
    success_path = []
    current_node = best_node
    parent_round = current_node.get('parent_round', -1)
    
    while parent_round != -1 and len(success_path) < max_ancestors:
        if parent_round not in history_map:
            break # æ‰¾åˆ°äº†å­¤å„¿èŠ‚ç‚¹ï¼Œåœæ­¢
        current_node = history_map[parent_round]
        
        entry_summary = (
            f"  (Round {current_node['round']}, Time: {current_node.get('time_ms', 0):.3f} ms)\n"
            f"    Goal: {current_node['goal']}\n"
        )
        # [!!! æ–°å¢ !!!] æ·»åŠ ç¥–å…ˆèŠ‚ç‚¹çš„é€‰å®š NCU æŒ‡æ ‡
        entry_summary += format_selected_ncu_metrics(current_node)
        
        success_path.append(entry_summary)
        parent_round = current_node.get('parent_round', -1)
        
    success_path.reverse() # ä» Root -> Best
    
    summary_str = "--- Recent Success Path (Root -> Current Best) ---\n"
    if not success_path:
        summary_str += "  (Current Best is Baseline)\n"
    else:
        summary_str += "\n".join(success_path)
        summary_str += f"\n  (Round {best_node['round']}, Current Best, Time: {best_node.get('time_ms', 0):.3f} ms)\n"
        # [!!! æ–°å¢ !!!] æ·»åŠ æœ€ä½³èŠ‚ç‚¹*æœ¬èº«*çš„é€‰å®š NCU æŒ‡æ ‡
        summary_str += format_selected_ncu_metrics(best_node)

    
    # 3. ç”Ÿæˆ "Recent Failed Attempts" (å­èŠ‚ç‚¹)
    failed_children = []
    best_round_id = best_node['round']
    
    # åå‘è¿­ä»£å†å²è®°å½•ä»¥é¦–å…ˆè·å–æœ€è¿‘çš„å¤±è´¥
    for entry in reversed(history):
        if entry.get('parent_round') == best_round_id and "Success" not in entry['status']:
            entry_summary = (
                f"  (Round {entry['round']})\n"
                f"    Goal: {entry['goal']}\n"
                f"    Status: {entry['status']}\n"
                f"    Details: {entry['details']}\n"
            )
            
            # [!!! æ–°å¢ !!!] æ·»åŠ å¤±è´¥å°è¯•çš„é€‰å®š NCU æŒ‡æ ‡
            entry_summary += format_selected_ncu_metrics(entry)
            
            # [!!! æ–°å¢ !!!] æ™ºèƒ½ä»£ç åŒ…å«
            if "Compilation" in entry['status'] or "Correctness" in entry['status']:
                failed_code = entry.get('code', '// Code not saved.')
                if failed_code:
                     entry_summary += f"    Failed Code:\n{failed_code}\n"
            
            failed_children.append(entry_summary)
            if len(failed_children) >= max_children:
                break
    
    failed_children.reverse() # é‡æ–°æŒ‰æ—¶é—´é¡ºåº
    
    summary_str += "\n\n--- Recent Failed Attempts (Based on this Best Kernel) ---\n"
    if not failed_children:
        summary_str += "  (No failed attempts recorded for this kernel yet.)\n"
    else:
        summary_str += "\n".join(failed_children)

    return summary_str


# [!!! å·²æ›´æ–° !!!] è§£å†³äº† TODO é—®é¢˜ 7 (æ¥è‡ªä¸Šä¸€ä¸ªè¯·æ±‚)
def format_metrics_for_llm(ptxas_metrics: dict, ncu_metrics: dict) -> str:
    """
    [!!! å·²æ›´æ–° !!!] è§£å†³äº† TODO é—®é¢˜ 7ã€‚
    æ­¤å‡½æ•°ç°åœ¨åŠ¨æ€åœ°å°† *æ‰€æœ‰* æ•è·çš„ NCU æŒ‡æ ‡ä¼ é€’ç»™ Planner Agentï¼Œ
    è€Œä¸æ˜¯ç¡¬ç¼–ç ä¸€ä¸ªå›ºå®šçš„ "Key" åˆ—è¡¨ã€‚
    """
    if not ncu_metrics:
        return "Hardware metrics are not yet available."
        
    summary = "=== PTXAS Compiler Metrics ===\n"
    summary += json.dumps(ptxas_metrics, indent=2)
    
    # [!!! æ›´æ”¹ !!!] ç›´æ¥ä½¿ç”¨å®Œæ•´çš„ ncu_metrics å­—å…¸ï¼Œå¹¶å°†æ ‡é¢˜æ›´æ”¹ä¸º "Full Set"
    summary += "\n\n=== NCU Hardware Metrics (Full Set) ===\n" 
    summary += json.dumps(ncu_metrics, indent=2)
    
    return summary


def main():
    print(f"Starting GEMM optimization for {config.MATRIX_N}x{config.MATRIX_N} matrix.")
    if not torch.cuda.is_available():
        print("âŒ é”™è¯¯ï¼šæœªæ£€æµ‹åˆ° CUDAã€‚æ— æ³•è¿›è¡Œæœ¬åœ°æµ‹è¯•ã€‚")
        sys.exit(1)
        
    print(f"Running on device: {config.DEVICE}")
    print(f"Total iteration rounds: {config.ITERATION_ROUNDS}")
    if config.MOCK_LLM_CALLS:
        print("--- è­¦å‘Š: MOCK LLM CALLS ARE ENABLED (in config.py) ---")
    
    # 1. åˆå§‹åŒ–
    N = config.MATRIX_N
    device = torch.device(config.DEVICE)
    print("Initializing Tensors...")
    torch.manual_seed(42)
    A_torch = torch.randn((N, N), dtype=torch.float32, device=device)
    B_torch = torch.randn((N, N), dtype=torch.float32, device=device)
    print("Running PyTorch baseline (torch.matmul) for reference...")
    C_ref_torch = torch.matmul(A_torch, B_torch) 
    
    cpp_source = kernels.CPP_SOURCE 
    
    # [!!! å·²æ›´æ–° !!!] åˆ‡æ¢åˆ°åŸºäºèŠ‚ç‚¹(Node)çš„è·Ÿè¸ª
    best_node = None
    current_ncu_metrics = {} # ä¿æŒä¸å˜ï¼šç”¨äº Tool Agent
    
    optimization_history = []
    
    if os.path.exists(config.HISTORY_FILE):
        print(f"Loading existing history from {config.HISTORY_FILE}")
        with open(config.HISTORY_FILE, 'r') as f:
            optimization_history = json.load(f)
        
        found_best = False
        # [!!! å·²æ›´æ–° !!!] æŸ¥æ‰¾æ€§èƒ½æœ€ä½³çš„èŠ‚ç‚¹
        best_time_so_far = float('inf')
        for entry in optimization_history:
             if ("Success" in entry['status']) and entry.get('code'):
                entry_time = entry.get('time_ms', float('inf'))
                if entry_time < best_time_so_far:
                    best_time_so_far = entry_time
                    best_node = entry # <--- æ‰¾åˆ°æœ€ä½³èŠ‚ç‚¹
                    found_best = True
        
        if found_best:
            print(f"Restored best kernel from history (Round {best_node['round']}, Time: {best_node['time_ms']:.3f} ms)")
            # [!!! å·²æ›´æ–° !!!] æ¢å¤ä¸Šä¸€è½®çš„ NCU æŒ‡æ ‡ä»¥ä¾› Tool Agent ä½¿ç”¨
            current_ncu_metrics = best_node.get('all_ncu_metrics', {})
        else:
             print("No successful kernel found in history, starting from baseline.")
             optimization_history = [] 
             
    # 2. è·å–åŸºçº¿æ€§èƒ½ (Round 0)
    if not optimization_history: 
        print("\n--- Round 0: Compiling and analyzing baseline (naive) kernel ---")
        current_module_name = "gemm_evolved_0"
        baseline_code = kernels.NAIVE_CUDA_SOURCE
        
        try:
            module, stdout_log, stderr_log = cuda_utils.load_gemm_module(
                cpp_source, 
                baseline_code, 
                module_name=current_module_name
            )
            print("Baseline kernel compiled successfully.")
            ptxas_metrics = cuda_utils.parse_ptxas_info(stdout_log + stderr_log)
            
            is_correct = cuda_utils.check_correctness(A_torch, B_torch, C_ref_torch)
            if not is_correct:
                print("âŒ Baseline kernel is INCORRECT. Exiting.")
                return
                
            print("Baseline kernel is correct. Benchmarking...")
            time_ms = cuda_utils.benchmark_kernel(A_torch, B_torch)
            
            print("Analyzing baseline kernel with NCU (this may take a while)...")
            ncu_metrics = cuda_utils.get_real_ncu_metrics(
                module.__file__, current_module_name, N
            )
            current_ncu_metrics = ncu_metrics # <--- è®¾ç½® "ä¸Šä¸€è½®" æŒ‡æ ‡
            
            # [!!! å·²æ›´æ–° !!!] è§£å†³äº† TODO é—®é¢˜ 5 å’Œ 6
            history_entry = {
                "round": 0, 
                "parent_round": -1, # <--- æ ‘çš„æ ¹èŠ‚ç‚¹
                "goal": "Baseline", 
                "status": "Success",
                "time_ms": time_ms, 
                "ptxas_metrics": ptxas_metrics,
                "all_ncu_metrics": ncu_metrics,
                "selected_ncu_metrics": [], # <--- åŸºçº¿æ²¡æœ‰é€‰æ‹©æŒ‡æ ‡
                "details": "Initial baseline measurement",
                "code": baseline_code 
            }
            optimization_history.append(history_entry)
            best_node = history_entry # <--- åŸºçº¿æ˜¯å½“å‰çš„æœ€ä½³èŠ‚ç‚¹
            print(f"Baseline performance: {time_ms:.3f} ms")

        except Exception as e:
            print(f"âŒ Baseline kernel failed compilation or runtime. Exiting. \n{e}")
            return
    
    # ç¡®ä¿æˆ‘ä»¬æœ‰ "best_node"
    if not best_node:
        print("âŒ é”™è¯¯ï¼šæœªèƒ½åˆå§‹åŒ– best_nodeã€‚å†å²è®°å½•å¯èƒ½å·²æŸåã€‚")
        return
        
    # ç¡®ä¿æˆ‘ä»¬æœ‰ "current_ncu_metrics"
    if not current_ncu_metrics: 
        current_ncu_metrics = best_node.get('all_ncu_metrics', {})


    # 3. å¼€å§‹ä¼˜åŒ–å¾ªç¯
    for i in tqdm(range(len(optimization_history), config.ITERATION_ROUNDS + 1), desc="Optimization Rounds"):
        if i == 0: continue # Round 0 å·²ç»å®Œæˆ
        
        print(f"\n--- Round {i}/{config.ITERATION_ROUNDS} ---")
        
        # [!!! å·²æ›´æ–° !!!] 
        # 1. ç¡®å®šæ­¤è½®çš„çˆ¶èŠ‚ç‚¹
        parent_node = best_node
        parent_round_id = parent_node['round']
        parent_kernel_code = parent_node['code']
        parent_time_ms = parent_node['time_ms']

        # 2. ç”Ÿæˆæ–°çš„æ ‘ä¸Šä¸‹æ–‡ï¼ˆç°åœ¨åŒ…å«æŒ‡æ ‡å’Œæ™ºèƒ½ä»£ç ï¼‰
        history_summary = summarize_tree_context(optimization_history, parent_node)
        
        # 3. æ ¼å¼åŒ–çˆ¶èŠ‚ç‚¹çš„æŒ‡æ ‡
        metrics_summary = format_metrics_for_llm(parent_node['ptxas_metrics'], parent_node['all_ncu_metrics'])
        
        print("------------------LXT:metrics_summary (to Planner)----------------------")
        print(metrics_summary)
        print("------------------LXT:metrics_summary (to Planner)----------------------")
        
        opt_goal = "N/A"
        bottleneck_analysis = "N/A" 
        detailed_plan = "N/A"
        new_kernel_code = None
        status = "Failed (Unknown)"
        details = ""
        new_time_ms = float('inf')
        new_ptxas_metrics = {}
        new_ncu_metrics = {}
        relevant_metric_names = [] 
        
        try:
            # 1. Planner Agent
            print("[Planner Agent] Analyzing hardware metrics and history...")
            planner_response = agents.call_llm(
                "planner", 
                prompts.PLANNER_SYSTEM_PROMPT,
                # [!!! å·²æ›´æ–° !!!] ä½¿ç”¨æ–°çš„æ ‘ä¸Šä¸‹æ–‡
                f"Optimization Tree Context:\n{history_summary}\n\n"
                f"=== Hardware Metrics for Current Best Kernel (Round {parent_round_id}) ===\n{metrics_summary}\n\n"
                f"Current Best C++/CUDA Source (Time: {parent_time_ms:.3f} ms):\n{parent_kernel_code}"
            )
            if not planner_response or "OPTIMIZATION_GOAL:" not in planner_response:
                status, details = "Failed (Planner)", "Planner did not return a valid goal."
                print(f"âŒ {status} {details}")
                continue 
            
            if "BOTTLENECK_ANALYSIS:" in planner_response:
                 bottleneck_analysis = planner_response.split("BOTTLENECK_ANALYSIS:")[1].split("OPTIMIZATION_GOAL:")[0].strip()
                 print(f"[Planner Agent] Bottleneck identified: {bottleneck_analysis}")
            else:
                status, details = "Failed (Planner)", "Planner did not output BOTTLENECK_ANALYSIS."
                print(f"âŒ {status} {details}")
                continue
                 
            opt_goal = planner_response.split("OPTIMIZATION_GOAL:")[1].strip()
            print(f"[Planner Agent] Goal: {opt_goal}")
            print("-----------------------LXT:planner_response----------------------")
            print(planner_response)
            print("-----------------------LXT:planner_response----------------------")
            
            # 2. Tool Agent
            print("[Tool Agent] Selecting metrics...")
            all_metric_names = list(current_ncu_metrics.keys())
            print("-----------------------LXT:all_metric_names----------------------")
            print(all_metric_names)
            print("-----------------------LXT:all_metric_names----------------------")
            if not all_metric_names:
                all_metric_names = config.BASE_NCU_METRICS_LIST_EXAMPLE
                
            tool_response = agents.call_llm(
                "tool", 
                prompts.TOOL_SYSTEM_PROMPT,
                f"All Available NCU Metric Names ({len(all_metric_names)}): {all_metric_names}\n\nOptimization Goal: {opt_goal}"
            )
            print("-----------------------LXT:tool_response----------------------")
            print(tool_response)
            print("-----------------------LXT:tool_response----------------------")
            
            relevant_metric_names = extract_metrics(tool_response)
            
            if not relevant_metric_names:
                status, details = "Failed (Tool)", "Tool Agent did not return a valid metric list."
                print(f"âŒ {status} {details}")
                continue 
            print(f"[Tool Agent] Selected {len(relevant_metric_names)} metrics: {relevant_metric_names}")
            
            # [!!! å·²æ›´æ–° !!!] æŒ‡æ ‡æ¥è‡ªçˆ¶èŠ‚ç‚¹
            relevant_metrics_dict = {
                metric: parent_node.get('all_ncu_metrics', {}).get(metric, 0.0) 
                for metric in relevant_metric_names
            }
            
            # 3. Analysis Agent [!!! å·²æ›´æ–° !!!]
            print("[Analysis Agent] Formulating plan...")
            analysis_response = agents.call_llm(
                "analysis", 
                prompts.ANALYSIS_SYSTEM_PROMPT,
                f"Planner's Bottleneck Analysis: {bottleneck_analysis}\n\n" 
                f"Optimization Goal: {opt_goal}\n\n"
                f"Optimization Tree Context:\n{history_summary}\n\n" # <--- ä¼ å…¥æ–°çš„æ ‘ä¸Šä¸‹æ–‡
                f"Current Best C++/CUDA Source:\n{parent_kernel_code}\n\n" # <--- æ˜ç¡®ä¼ å…¥çˆ¶èŠ‚ç‚¹ä»£ç 
                f"Current Best Hardware Metrics (Full Set): {metrics_summary}\n\n" 
                f"Tool-Selected Metrics from *Previous* Run (Values): {relevant_metrics_dict}" 
            )
            print("-----------------------LXT:analysis_response----------------------")
            print(analysis_response)
            print("-----------------------LXT:analysis_response----------------------")
            if not analysis_response or "DETAILED_PLAN:" not in analysis_response:
                status, details = "Failed (Analysis)", "Analysis Agent did not return a valid plan."
                print(f"âŒ {status} {details}")
                continue 
            detailed_plan = analysis_response.split("DETAILED_PLAN:")[1].strip()

            # 4. Coder Agent
            print("[Coder Agent] Generating new kernel...")
            coder_response = agents.call_llm(
                "coder", 
                prompts.CODER_SYSTEM_PROMPT,
                f"Original C++/CUDA Source:\n{parent_kernel_code}\n\nDetailed Plan:\n{detailed_plan}" # <--- åŸºäºçˆ¶èŠ‚ç‚¹ä»£ç ä¿®æ”¹
            )
            print("-----------------------LXT:coder_response----------------------")
            print(coder_response)
            print("-----------------------LXT:coder_response----------------------")
            new_kernel_code = extract_code(coder_response)
            if not new_kernel_code:
                status, details = "Failed (Coder)", "Coder Agent did not produce valid code."
                print(f"âŒ {status} {details}")
                continue 
            print("[Coder Agent] New kernel source generated.")
                
            # 5. éªŒè¯å’Œåˆ†æ
            current_module_name = f"gemm_evolved_{i}" 
            print(f"Compiling new kernel (module: {current_module_name})...")
            
            try:
                module, stdout_log, stderr_log = cuda_utils.load_gemm_module(
                    cpp_source, 
                    new_kernel_code, 
                    module_name=current_module_name
                )
                print("Compilation successful.")
                new_ptxas_metrics = cuda_utils.parse_ptxas_info(stdout_log + stderr_log)
                
                is_correct = cuda_utils.check_correctness(A_torch, B_torch, C_ref_torch)
                if not is_correct:
                    status, details = "Failed (Correctness)", "New kernel is INCORRECT."
                    print(f"âŒ {status}")
                    continue 
                    
            except Exception as e:
                status, details = "Failed (Compilation)", str(e)
                print(f"âŒ {status}")
                continue 
                
            print("New kernel is CORRECT. Benchmarking...")
            
            new_time_ms = cuda_utils.benchmark_kernel(A_torch, B_torch)
            print("Analyzing new kernel with NCU...")
            
            new_ncu_metrics = cuda_utils.get_real_ncu_metrics(
                module.__file__, 
                current_module_name, 
                N
            )
            
            # [!!! å·²æ›´æ–° !!!] ä¸çˆ¶èŠ‚ç‚¹(best_node)æ¯”è¾ƒ
            if new_time_ms < parent_time_ms: 
                status = "Success (New Best)"
                details = f"Performance improved from {parent_time_ms:.3f} ms to {new_time_ms:.3f} ms."
                print(f"âœ… {status} {details}")
            else:
                status = "Failed (Performance Regression)"
                details = f"New time {new_time_ms:.3f} ms is not better than parent time {parent_time_ms:.3f} ms."
                print(f"âŒ {status} {details}")
            
            current_ncu_metrics = new_ncu_metrics

        except Exception as e:
            status, details = "Failed (Unhandled Exception)", str(e)
            print(f"âŒ {status} {details}")
            
        finally:
            # [!!! å·²æ›´æ–° !!!] è§£å†³äº† TODO é—®é¢˜ 5 å’Œ 6
            # åˆ›å»ºæ–°çš„å†å²èŠ‚ç‚¹
            history_entry = {
                "round": i,
                "parent_round": parent_round_id, # <--- è®¾ç½®çˆ¶èŠ‚ç‚¹
                "goal": opt_goal,
                "status": status,
                "time_ms": new_time_ms if new_time_ms != float('inf') else None,
                "ptxas_metrics": new_ptxas_metrics,
                "all_ncu_metrics": new_ncu_metrics,
                "selected_ncu_metrics": relevant_metric_names,
                "details": details,
                "code": new_kernel_code if new_kernel_code else "" 
            }
            optimization_history.append(history_entry)

            # [!!! å·²æ›´æ–° !!!] å¦‚æœæˆåŠŸï¼Œæ›´æ–° best_node
            # æˆ‘ä»¬éœ€è¦æ¯”è¾ƒ new_time_ms å’Œ best_node['time_ms'] (å…¨å±€æœ€ä½³)
            if status == "Success (New Best)" and new_time_ms < best_node['time_ms']:
                print(f"ğŸ‘‘ New Global Best! (Round {i}, Time: {new_time_ms:.3f} ms)")
                best_node = history_entry
            # å¦‚æœå¤±è´¥ï¼Œæˆ–è€…åªæ˜¯æ¯”çˆ¶èŠ‚ç‚¹å¥½ä½†ä¸æ˜¯å…¨å±€æœ€å¥½ï¼Œ
            # best_node ä¿æŒä¸å˜ï¼Œä¸‹ä¸€è½®å°†ä»*å…¨å±€æœ€ä½³*å†æ¬¡å°è¯•
            # (æ³¨æ„ï¼šè¿™é‡Œçš„é€»è¾‘æ˜¯ "å§‹ç»ˆä»å…¨å±€æœ€ä½³èŠ‚ç‚¹åˆ†æ”¯")
            # (å¦‚æœæƒ³ä» "åˆšåˆšæˆåŠŸçš„çˆ¶èŠ‚ç‚¹" åˆ†æ”¯ï¼Œåº”ä½¿ç”¨:
            #  if status == "Success (New Best)": best_node = history_entry)
            # æˆ‘ä»¬å°†åšæŒ "å§‹ç»ˆä»å…¨å±€æœ€ä½³åˆ†æ”¯" çš„ç­–ç•¥ã€‚

    # 4. æœ€ç»ˆæŠ¥å‘Š
    print("\n--- Optimization Finished ---")
    if optimization_history:
        print(f"Baseline performance (Round 0): {optimization_history[0].get('time_ms', 0.0):.3f} ms")
    print(f"Best kernel performance (Round {best_node['round']}): {best_node['time_ms']:.3f} ms")
    
    final_kernel_path = "best_gemm_kernel.cu"
    with open(final_kernel_path, "w") as f:
        f.write(best_node['code']) # <--- å†™å…¥æœ€ä½³èŠ‚ç‚¹çš„ä»£ç 
    print(f"Best kernel C++/CUDA source saved to {final_kernel_path}")
    
    with open(config.HISTORY_FILE, 'w') as f:
        json.dump(optimization_history, f, indent=2)
    print(f"Optimization history saved to {config.HISTORY_FILE}")
    
    # 5. è¿è¡Œæœ€ç»ˆåŸºå‡†æµ‹è¯•
    print("\n--- Running Final Benchmark ---")
    pytorch_time_ms = cuda_utils.get_pytorch_performance(A_torch, B_torch)
    print(f"PyTorch (torch.matmul) performance: {pytorch_time_ms:.3f} ms")
    print(f"Our best LLM-optimized kernel: {best_node['time_ms']:.3f} ms")
    
    speedup = pytorch_time_ms / best_node['time_ms']
    if best_node['time_ms'] < pytorch_time_ms:
        print(f"SUCCESS: Optimized kernel is {speedup:.2f}x faster than PyTorch!")
    else:
        print(f"Result: PyTorch is {1/speedup:.2f}x faster.")

if __name__ == "__main__":
    main()